{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_PCA_vecs = np.load('train_PCA_vecs.npy')\n",
    "train_LDA_vecs = np.load('train_LDA_vecs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2576, 279)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_PCA_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 39)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_LDA_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = []\n",
    "train_labels = [] # 1...40\n",
    "for c in range(40):\n",
    "    for n in range(7):\n",
    "        img = Image.open('hw2_data/hw2-2_data/{}_{}.png'.format(c+1,n+1)).convert('L')\n",
    "        img_as_np = np.asarray(img)\n",
    "        train_imgs.append(img_as_np.reshape(-1).astype(float))\n",
    "        train_labels.append(c+1)\n",
    "train_imgs = np.array(train_imgs)\n",
    "mean_img = train_imgs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 2576)\n",
      "280\n",
      "(2576,)\n"
     ]
    }
   ],
   "source": [
    "print(train_imgs.shape)\n",
    "print(len(train_labels))\n",
    "print(mean_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = []\n",
    "test_labels = [] # 1...40\n",
    "for c in range(40):\n",
    "    for n in range(7,10):\n",
    "        img = Image.open('hw2_data/hw2-2_data/{}_{}.png'.format(c+1,n+1)).convert('L')\n",
    "        img_as_np = np.asarray(img)\n",
    "        test_imgs.append(img_as_np.reshape(-1).astype(float))\n",
    "        test_labels.append(c+1)\n",
    "test_imgs = np.array(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 2576)\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "print(test_imgs.shape)\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = [i for i in range(7)]\n",
    "shuffle(idxs)\n",
    "val_idxs = np.array_split(idxs,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 4, 3]), array([6, 5]), array([2, 1])]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_acc(K, train_imgs_dim_reduced, train_labels, test_imgs_dim_reduced, test_labels): # prints accuracy\n",
    "    neigh = KNeighborsClassifier(n_neighbors=K)\n",
    "    neigh.fit(train_imgs_dim_reduced, train_labels)\n",
    "    \n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    pred_labels = neigh.predict(test_imgs_dim_reduced)\n",
    "    # print('pred_labels.shape', pred_labels.shape)\n",
    "    return (pred_labels == test_labels).sum() / len(test_labels)\n",
    "    \n",
    "    # print('accuracy:', correct_count / total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maoredman/.pyenv/versions/3.6.4/lib/python3.6/site-packages/ipykernel_launcher.py:28: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 3   K: 1   val_acc: 0.6888888888888889\n",
      "N: 3   K: 3   val_acc: 0.6124999999999999\n",
      "N: 3   K: 5   val_acc: 0.5513888888888888\n",
      "N: 10   K: 1   val_acc: 0.8888888888888888\n",
      "N: 10   K: 3   val_acc: 0.7819444444444446\n",
      "N: 10   K: 5   val_acc: 0.7013888888888888\n",
      "N: 39   K: 1   val_acc: 0.9180555555555556\n",
      "N: 39   K: 3   val_acc: 0.8722222222222222\n",
      "N: 39   K: 5   val_acc: 0.7805555555555556\n",
      "\n",
      "best_N: 39   best_K: 1   best_val_acc: 0.9180555555555556\n",
      "test_acc: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "NUM_FOLDS = 3\n",
    "K_options = [1,3,5]\n",
    "N_options = [3,10,39]\n",
    "\n",
    "best_acc, best_N, best_k = 0, 0, 0\n",
    "for N in N_options:\n",
    "    for K in K_options:\n",
    "        mean_acc = 0\n",
    "        for fold in range(NUM_FOLDS):\n",
    "            my_train = []\n",
    "            my_train_labels = []\n",
    "            \n",
    "            my_val = []\n",
    "            my_val_labels = []\n",
    "            for idx, img in enumerate(train_imgs):\n",
    "                if idx % 7 in val_idxs[fold]:\n",
    "                    my_val.append(img)\n",
    "                    my_val_labels.append(train_labels[idx])\n",
    "                else:\n",
    "                    my_train.append(img)\n",
    "                    my_train_labels.append(train_labels[idx])\n",
    "            my_train = np.array(my_train)\n",
    "            my_val = np.array(my_val)\n",
    "            my_mean_img = my_train.mean(axis=0)\n",
    "            \n",
    "            train_cov_matrix = np.cov(my_train.reshape(-1,2576).T)\n",
    "            train_eig_vals, train_eig_vecs = np.linalg.eig(train_cov_matrix)\n",
    "            train_eig_vecs = train_eig_vecs.astype(float)\n",
    "            \n",
    "            train_imgs_PCA = (my_train - my_mean_img).dot(train_eig_vecs[:,0:N])\n",
    "            val_imgs_PCA = (my_val - my_mean_img).dot(train_eig_vecs[:,0:N])            \n",
    "\n",
    "            mean_acc += KNN_acc(K, train_imgs_PCA, my_train_labels, val_imgs_PCA, my_val_labels) / NUM_FOLDS\n",
    "        print('N: {}   K: {}   val_acc: {}'.format(N, K, mean_acc))\n",
    "        if mean_acc > best_acc:\n",
    "            best_acc = mean_acc\n",
    "            best_N = N\n",
    "            best_K = K\n",
    "print()\n",
    "print('best_N: {}   best_K: {}   best_val_acc: {}'.format(best_N, best_K, best_acc))\n",
    "\n",
    "train_imgs_PCA = (train_imgs - mean_img).dot(train_PCA_vecs[:,0:best_N])\n",
    "test_imgs_PCA = (test_imgs - mean_img).dot(train_PCA_vecs[:,0:best_N])\n",
    "test_acc = KNN_acc(best_K, train_imgs_PCA, train_labels, test_imgs_PCA, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "train_imgs_LDA = (train_imgs - mean_img).dot(train_PCA_vecs[:,0:train_LDA_vecs.shape[0]]).dot(train_LDA_vecs[:,0:N])\n",
    "test_imgs_LDA = (test_imgs - mean_img).dot(train_PCA_vecs[:,0:train_LDA_vecs.shape[0]]).dot(train_LDA_vecs[:,0:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 2576)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maoredman/.pyenv/versions/3.6.4/lib/python3.6/site-packages/ipykernel_launcher.py:31: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/maoredman/.pyenv/versions/3.6.4/lib/python3.6/site-packages/ipykernel_launcher.py:56: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 3   K: 1   val_acc: 0.41944444444444445\n",
      "N: 3   K: 3   val_acc: 0.4152777777777778\n",
      "N: 3   K: 5   val_acc: 0.4138888888888889\n",
      "N: 10   K: 1   val_acc: 0.7833333333333332\n",
      "N: 10   K: 3   val_acc: 0.7833333333333332\n",
      "N: 10   K: 5   val_acc: 0.786111111111111\n",
      "N: 39   K: 1   val_acc: 0.9236111111111112\n",
      "N: 39   K: 3   val_acc: 0.9291666666666667\n",
      "N: 39   K: 5   val_acc: 0.9319444444444445\n",
      "\n",
      "best_N: 39   best_K: 5   best_val_acc: 0.9319444444444445\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [280, 200]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-448e3db75f3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mtest_imgs_LDA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_imgs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_PCA_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_LDA_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_LDA_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbest_N\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mmean_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mKNN_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_K\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_imgs_LDA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_train_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_imgs_LDA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_val_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mNUM_FOLDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_acc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-df8ad725808d>\u001b[0m in \u001b[0;36mKNN_acc\u001b[0;34m(K, train_imgs_dim_reduced, train_labels, test_imgs_dim_reduced, test_labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mKNN_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_imgs_dim_reduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_imgs_dim_reduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# prints accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mneigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mneigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_imgs_dim_reduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcorrect_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \"\"\"\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [280, 200]"
     ]
    }
   ],
   "source": [
    "NUM_FOLDS = 3\n",
    "K_options = [1,3,5]\n",
    "N_options = [3,10,39]\n",
    "\n",
    "best_acc, best_N, best_k = 0, 0, 0\n",
    "for N in N_options:\n",
    "    for K in K_options:\n",
    "        mean_acc = 0\n",
    "        for fold in range(NUM_FOLDS):\n",
    "            my_train = []\n",
    "            my_train_labels = []\n",
    "            \n",
    "            my_val = []\n",
    "            my_val_labels = []\n",
    "            for idx, img in enumerate(train_imgs):\n",
    "                if idx % 7 in val_idxs[fold]:\n",
    "                    my_val.append(img)\n",
    "                    my_val_labels.append(train_labels[idx])\n",
    "                else:\n",
    "                    my_train.append(img)\n",
    "                    my_train_labels.append(train_labels[idx])\n",
    "            my_train = np.array(my_train)\n",
    "            my_val = np.array(my_val)\n",
    "            my_mean_img = my_train.mean(axis=0)\n",
    "#             print('my_train.shape', my_train.shape)\n",
    "#             print('my_mean_img.shape', my_mean_img.shape)\n",
    "#             print('my_val.shape', my_val.shape)\n",
    "            \n",
    "            train_cov_matrix = np.cov(my_train.reshape(-1,2576).T)\n",
    "            train_eig_vals, train_eig_vecs = np.linalg.eig(train_cov_matrix)\n",
    "            train_eig_vecs = train_eig_vecs.astype(float)\n",
    "            \n",
    "            eigenfaces_used = len(my_train)-40\n",
    "            train_imgs_PCA = (my_train - my_mean_img).dot(train_eig_vecs[:,0:eigenfaces_used])\n",
    "            val_imgs_PCA = (my_val - my_mean_img).dot(train_eig_vecs[:,0:eigenfaces_used])\n",
    "            \n",
    "            S_W = np.zeros((eigenfaces_used, eigenfaces_used))\n",
    "            class_means = []\n",
    "            for target_label in range(1,41):\n",
    "                x = []\n",
    "                for idx, label in enumerate(my_train_labels):\n",
    "                    if label == target_label:\n",
    "                        x.append(train_imgs_PCA[idx])\n",
    "                x = np.array(x)\n",
    "                class_mean = x.mean(axis=0)\n",
    "                class_means.append(class_mean)\n",
    "                x_minus_u = x - class_mean\n",
    "                S_W += (x_minus_u.T).dot(x_minus_u)\n",
    "            class_means = np.array(class_means)\n",
    "            \n",
    "            PCA_global_mean = train_imgs_PCA.mean(axis=0)\n",
    "            u_class_minus_u_global = class_means - PCA_global_mean\n",
    "            S_B = (u_class_minus_u_global.T).dot(u_class_minus_u_global)\n",
    "                \n",
    "            LDA_eig_vals, W = np.linalg.eig(inv(S_W).dot(S_B))\n",
    "            W = W.astype(float)\n",
    "            \n",
    "            train_imgs_LDA = train_imgs_PCA.dot(W[:,0:N])\n",
    "            val_imgs_LDA = val_imgs_PCA.dot(W[:,0:N])\n",
    "                \n",
    "            mean_acc += KNN_acc(K, train_imgs_LDA, my_train_labels, val_imgs_LDA, my_val_labels) / NUM_FOLDS\n",
    "        print('N: {}   K: {}   val_acc: {}'.format(N, K, mean_acc))\n",
    "        if mean_acc > best_acc:\n",
    "            best_acc = mean_acc\n",
    "            best_N = N\n",
    "            best_K = K\n",
    "print()\n",
    "print('best_N: {}   best_K: {}   best_val_acc: {}'.format(best_N, best_K, best_acc))\n",
    "\n",
    "train_imgs_LDA = (train_imgs - mean_img).dot(train_PCA_vecs[:,0:train_LDA_vecs.shape[0]]).dot(train_LDA_vecs[:,0:best_N])\n",
    "test_imgs_LDA = (test_imgs - mean_img).dot(train_PCA_vecs[:,0:train_LDA_vecs.shape[0]]).dot(train_LDA_vecs[:,0:best_N])\n",
    "\n",
    "test_acc = KNN_acc(best_K, train_imgs_LDA, train_labels, test_imgs_LDA, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "test_acc = KNN_acc(best_K, train_imgs_LDA, train_labels, test_imgs_LDA, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
